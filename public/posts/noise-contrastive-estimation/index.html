<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Noise constrastive estimation | iamtu</title>
<meta name=keywords content="learning,probabilistic-ml"><meta name=description content="TLDR The paper proposed a method to estimate the probability density function of a dataset by discriminating observed data and noise drawn from a distribution. The paper setups the problem into a dataset of \(T\) observations \((x_1, &mldr; x_T)\) drawn from a true distribution \(p_d(.)\). We then try to approximate \(p_d\) by a parameterized function \(p_m(.;\theta)\). The estimator \(\hat{\theta}_T\) is defined to be the \(\theta\) that maximize function
$$ J_T(\theta) = \frac{1}{2T}\sum_t{\log[h(x_t; 0)]} + \log[1-h(y_t; \theta)] $$"><meta name=author content="Tu T. Do"><link rel=canonical href=http://localhost:1313/posts/noise-contrastive-estimation/><meta name=google-site-verification content="G-PWLR4FLELZ"><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/noise-contrastive-estimation/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-PWLR4FLELZ"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-PWLR4FLELZ")}</script><meta property="og:title" content="Noise constrastive estimation"><meta property="og:description" content="TLDR The paper proposed a method to estimate the probability density function of a dataset by discriminating observed data and noise drawn from a distribution. The paper setups the problem into a dataset of \(T\) observations \((x_1, &mldr; x_T)\) drawn from a true distribution \(p_d(.)\). We then try to approximate \(p_d\) by a parameterized function \(p_m(.;\theta)\). The estimator \(\hat{\theta}_T\) is defined to be the \(\theta\) that maximize function
$$ J_T(\theta) = \frac{1}{2T}\sum_t{\log[h(x_t; 0)]} + \log[1-h(y_t; \theta)] $$"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/noise-contrastive-estimation/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-23T00:00:00+00:00"><meta property="article:modified_time" content="2023-09-23T00:00:00+00:00"><meta property="og:site_name" content="iamtu"><meta name=twitter:card content="summary"><meta name=twitter:title content="Noise constrastive estimation"><meta name=twitter:description content="TLDR The paper proposed a method to estimate the probability density function of a dataset by discriminating observed data and noise drawn from a distribution. The paper setups the problem into a dataset of \(T\) observations \((x_1, &mldr; x_T)\) drawn from a true distribution \(p_d(.)\). We then try to approximate \(p_d\) by a parameterized function \(p_m(.;\theta)\). The estimator \(\hat{\theta}_T\) is defined to be the \(\theta\) that maximize function
$$ J_T(\theta) = \frac{1}{2T}\sum_t{\log[h(x_t; 0)]} + \log[1-h(y_t; \theta)] $$"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Noise constrastive estimation","item":"http://localhost:1313/posts/noise-contrastive-estimation/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Noise constrastive estimation","name":"Noise constrastive estimation","description":"TLDR The paper proposed a method to estimate the probability density function of a dataset by discriminating observed data and noise drawn from a distribution. The paper setups the problem into a dataset of \\(T\\) observations \\((x_1, \u0026hellip; x_T)\\) drawn from a true distribution \\(p_d(.)\\). We then try to approximate \\(p_d\\) by a parameterized function \\(p_m(.;\\theta)\\). The estimator \\(\\hat{\\theta}_T\\) is defined to be the \\(\\theta\\) that maximize function\n$$ J_T(\\theta) = \\frac{1}{2T}\\sum_t{\\log[h(x_t; 0)]} + \\log[1-h(y_t; \\theta)] $$","keywords":["learning","probabilistic-ml"],"articleBody":"TLDR The paper proposed a method to estimate the probability density function of a dataset by discriminating observed data and noise drawn from a distribution. The paper setups the problem into a dataset of \\(T\\) observations \\((x_1, … x_T)\\) drawn from a true distribution \\(p_d(.)\\). We then try to approximate \\(p_d\\) by a parameterized function \\(p_m(.;\\theta)\\). The estimator \\(\\hat{\\theta}_T\\) is defined to be the \\(\\theta\\) that maximize function\n$$ J_T(\\theta) = \\frac{1}{2T}\\sum_t{\\log[h(x_t; 0)]} + \\log[1-h(y_t; \\theta)] $$\nIn which:\n\\(y=(y_1, …, y_T)\\) be a dataset of \\(T\\) observations draw from a noise density function $p_n(.)$. \\(h(u; \\theta) = 1/(1 + e^{-G(u;\\theta)})\\) \\(G(u; \\theta) = \\log p_m(u; \\theta) - \\log p_n(u)\\) For \\(p_m(.; \\theta)\\) to be a valid p.d.f, we also need to include unit integral constraint into the optimization problem, that is \\(\\int_x{p_m(x; \\theta)dx} = 1\\). However, this integral is often intractable in most cases, for example, when we use a neural network to parameterize \\(p_m(.;\\theta)\\).\nInterestingly, the paper claims that maximizing the objective function gives a valid p.d.f without placing the unit integral constraint on the optimization (Theorem 1). In this post, I’ll attempt to prove the theorem as an exercise. Note that, I made an assumption that support of $x$ and $y$ are equal (in eq.7); which mean $p_n(.)$ is nonzero whenever $p_d(.)$ is nonzero and $p_n(.)$ is zero everywhere else.\nProof of threorem I When the sample size $T$ becomes arbitrarily large, the objective function $J_T(\\theta)$ converges in probability (this is a new word for me) to $\\tilde{J}$\n\\begin{equation} \\begin{aligned} \\tilde{J}(\\theta) = \\frac{1}{2}\\mathbb{E}_{x, y} { \\log{r\\big(f(x) - \\log{p_n(x)}\\big)} + \\log{\\big[ 1 - r\\big(f(y) - \\log{p_n(y)}\\big) \\big]} } \\end{aligned} \\end{equation}\nIn which \\(f(x) = \\log p_m(x; \\theta)\\) is the function approximating log-likelihood the true distribution $p_d(.)$.\nNotation \\(p_d(x)\\) true probability density function (p.d.f) of data. \\(p_n(x)\\) p.d.f of noise generating distribution. \\(r(x) = \\frac{1}{1+\\exp(-x)}\\) sigmoid function. \\(X = (x_1, … x_T); x \\sim p_d(x)\\) be the dataset of T observations. \\(Y = (y_1, … y_T); y \\sim p_n(y)\\) be the dataset of T artificially generated noise. \\(p_m(.; \\theta)\\) is estimation of \\(p_d(.)\\) parameterized by \\(\\theta\\). Theorem \\(\\tilde{J}\\) attains a maximum at \\(f(.) = \\log p_d(.)\\). There are no other extrema if the noise density \\(p_n(.)\\) is chosen such it is nonzero whenever \\(p_d(.)\\) is nonzero.\nProof Let \\(\\hat{f}(x)\\) be the optimal function that maximizes \\(\\tilde{J}\\), and \\(f(x)=\\hat{f}(x) + \\epsilon\\eta(x)\\).\n\\begin{equation} \\begin{aligned} \\tilde{J}(\\theta) \u0026= K(\\epsilon) \\\\ \u0026= \\frac{1}{2}\\mathbb{E}_{x, y} { \\log{ r\\big(f(x) - \\log{p_n(x)}\\big) } + \\log{\\big[ 1 - r\\big(f(y) - \\log{p_n(y)}\\big) \\big]} } \\\\ \u0026= \\frac{1}{2}\\underbrace{ \\mathbb{E}_x { \\log r\\big( f(x) - \\log p_n(x) \\big) } }_A + \\frac{1}{2} \\underbrace{\\mathbb{E}_y { \\log{\\big[ 1 - r\\big(f(y) - \\log{p_n(y)}\\big) \\big]} }}_B \\\\ \\implies \\frac{dK}{d\\epsilon} \u0026= \\frac{dA}{d\\epsilon} + \\frac{dB}{d\\epsilon} \\end{aligned} \\end{equation}\nExpand the first term of $K(\\epsilon)$\n\\begin{equation} \\begin{aligned} A(\\epsilon) \u0026= \\mathbb{E}_x { \\log r\\big( f(x) - \\log p_n(x) \\big) } \\\\ \u0026 = \\int_x { p_d(x) \\log{ r\\big( \\hat{f}(x) + \\epsilon \\eta(x) - \\log p_n(x) \\big) } dx } \\end{aligned} \\end{equation}\nTaking derivative of $A(\\epsilon)$\n\\begin{equation} \\begin{aligned} \\frac{dA}{d\\epsilon} \u0026= \\frac{1}{d\\epsilon} \\int_x { p_d(x) \\log{ r\\big( \\hat{f}(x) + \\epsilon \\eta(x) - \\log p_n(x) \\big) } dx } \\\\ \u0026 = \\int_x { p_d(x) \\big[ \\frac{1}{d\\epsilon}\\log{ r \\big( \\underbrace{ \\hat{f}(x) + \\epsilon \\eta(x) - \\log p_n(x) }_{g(\\epsilon)} \\big) } \\big]dx } \\\\ \u0026 = \\int_x{ p_d(x) \\frac{d\\log{r}}{dr} \\frac{dr}{dg} \\frac{dg}{d\\epsilon} dx } \\\\ \u0026 = \\int_x{ p_d(x) \\frac{1}{r} r(1-r) \\eta(x) dx } \\\\ \u0026 = \\int_x{ p_d(x) \\big[1 - r\\big( \\hat{f}(x) + \\epsilon \\eta(x) - \\log p_n(x)\\big) \\big] \\eta(x) dx } \\end{aligned} \\end{equation}\nNow let’s turn our attention to the second term of $K(\\epsilon)$\n\\begin{equation} \\begin{aligned} B(\\epsilon) \u0026= \\mathbb{E}_y { \\log\\big[ 1 - r\\big(f(y) - \\log{p_n(y)}\\big) \\big] } \\\\ \u0026 = \\int_y { p_n(y) \\log \\big[ 1 - r \\big( \\underbrace{ \\hat{f}(y) + \\epsilon \\eta(y) - \\log p_n(y) }_h \\big) \\big]dy } \\end{aligned} \\end{equation}\nTaking derivative of $B$ w.r.t $\\epsilon$\n\\begin{equation} \\begin{aligned} \\frac{dB}{d\\epsilon} \u0026= \\frac{1}{d\\epsilon} \\int_y{ p_n(y)\\log{ \\big[ 1 - r\\big( h(\\epsilon)\\big) \\big] }dy } \\\\ \u0026= \\int_y { p_n(y) \\frac{d\\log(1-r)}{d(1-r)} \\frac{d(1-r)}{dr} \\frac{dr}{dh} \\frac{dh}{d\\epsilon} dy } \\\\ \u0026 = \\int_y { p_n(y) \\frac{1}{1-r} (-1) r(1-r) \\eta(y) } \\\\ \u0026 = -\\int_y{ p_n(y) r\\big( \\hat{f}(y) + \\epsilon \\eta(y) - \\log p_n(y) \\big) \\eta(y) dy } \\end{aligned} \\end{equation}\nSubstitute result from eq(4) and eq(6) to eq(2), $\\frac{dK}{d\\epsilon}$ is evaluated to $0$ at $\\epsilon = 0$.\n\\begin{equation} \\begin{aligned} \\frac{dK}{d\\epsilon}\\big\\vert_{\\epsilon=0} \u0026= \\frac{dA}{d\\epsilon}\\big\\vert_{\\epsilon=0} + \\frac{dB}{d\\epsilon}\\big\\vert_{\\epsilon=0} \\\\ \u0026= \\int_x { p_d(x) \\big[1 - r\\big( \\hat{f}(x) - \\log p_n(x)\\big) \\big] \\eta(x) dx } \\\\ \u0026 - \\int_y{ p_n(y) r \\big( \\hat{f}(y) - \\log p_n(y) \\big) \\eta(y) dy } \\\\ \u0026 = 0 \\end{aligned} \\end{equation}\nConsider eq. (7), if the support for $x$ and $y$ are equal, which mean we integrate $x$ and $y$ over a same region, we can change $y$ to $x$ and rewrite eq.(7) as\n\\begin{equation} \\begin{aligned} \\frac{dK}{d\\epsilon} \\big\\vert_{\\epsilon = 0} \u0026= \\int_x { \\underbrace{ p_d(x) \\big[1 - r\\big( \\hat{f}(x) - \\log p_n(x)\\big) \\big] }_C \\eta(x) dx } \\\\ \u0026 - \\int_x{ \\underbrace{ p_n(x) r \\big( \\hat{f}(x) - \\log p_n(x) \\big) }_D \\eta(x) dx } \\\\ \u0026 = \\int_x{(C-D)\\eta(x)dx} = 0 \\quad \\forall \\eta(x) \\end{aligned} \\end{equation}\nThe equality in eq.(8) happend if and only if \\(C=D\\). This result easily leads to \\(\\hat{f}(x) = \\log p_d(x)\\).\nReferences Noise-contrastive estimation: A new estimation principle for unnormalized statistical models ","wordCount":"868","inLanguage":"en","datePublished":"2023-09-23T00:00:00Z","dateModified":"2023-09-23T00:00:00Z","author":{"@type":"Person","name":"Tu T. Do"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/noise-contrastive-estimation/"},"publisher":{"@type":"Organization","name":"iamtu","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="iamtu (Alt + H)">iamtu</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/ title=home><span>home</span></a></li><li><a href=http://localhost:1313/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=http://localhost:1313/categories/ title=categories><span>categories</span></a></li><li><a href=http://localhost:1313/about/ title=about><span>about</span></a></li><li><a href=http://localhost:1313/archives/ title=archives><span>archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class=post-title>Noise constrastive estimation</h1><div class=post-meta><span title='2023-09-23 00:00:00 +0000 UTC'>September 23, 2023</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;868 words&nbsp;·&nbsp;Tu T. Do</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#tldr aria-label=TLDR>TLDR</a></li><li><a href=#proof-of-threorem-i aria-label="Proof of threorem I">Proof of threorem I</a><ul><li><a href=#notation aria-label=Notation>Notation</a></li><li><a href=#theorem aria-label=Theorem>Theorem</a></li><li><a href=#proof aria-label=Proof>Proof</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h2 id=tldr>TLDR<a hidden class=anchor aria-hidden=true href=#tldr>#</a></h2><p>The <a href=https://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf>paper</a> proposed a method to estimate the probability density function of a dataset by discriminating observed data and noise drawn from a distribution. The paper setups the problem into a dataset of \(T\) observations \((x_1, &mldr; x_T)\) drawn from a true distribution \(p_d(.)\). We then try to approximate \(p_d\) by a parameterized function \(p_m(.;\theta)\). The estimator \(\hat{\theta}_T\) is defined to be the \(\theta\) that maximize function</p><p>$$
J_T(\theta) = \frac{1}{2T}\sum_t{\log[h(x_t; 0)]} + \log[1-h(y_t; \theta)]
$$</p><p>In which:</p><ul><li>\(y=(y_1, &mldr;, y_T)\) be a dataset of \(T\) observations draw from a noise density function $p_n(.)$.</li><li>\(h(u; \theta) = 1/(1 + e^{-G(u;\theta)})\)</li><li>\(G(u; \theta) = \log p_m(u; \theta) - \log p_n(u)\)</li></ul><p>For \(p_m(.; \theta)\) to be a valid p.d.f, we also need to include unit integral constraint into the optimization problem, that is \(\int_x{p_m(x; \theta)dx} = 1\). However, this integral is often intractable in most cases, for example, when we use a neural network to parameterize \(p_m(.;\theta)\).</p><p>Interestingly, the paper claims that maximizing the objective function gives a valid p.d.f without placing the unit integral constraint on the optimization (Theorem 1). In this post, I&rsquo;ll attempt to prove the theorem as an exercise. Note that, I made an assumption that support of $x$ and $y$ are equal (in eq.7); which mean $p_n(.)$ is nonzero whenever $p_d(.)$ is nonzero and $p_n(.)$ is zero everywhere else.</p><h2 id=proof-of-threorem-i>Proof of threorem I<a hidden class=anchor aria-hidden=true href=#proof-of-threorem-i>#</a></h2><p>When the sample size $T$ becomes arbitrarily large, the objective function $J_T(\theta)$ converges in probability (this is a new word for me) to $\tilde{J}$</p><p>\begin{equation}
\begin{aligned}
\tilde{J}(\theta) = \frac{1}{2}\mathbb{E}_{x, y} {
\log{r\big(f(x) - \log{p_n(x)}\big)}
+ \log{\big[
1 - r\big(f(y) - \log{p_n(y)}\big)
\big]}
}
\end{aligned}
\end{equation}</p><p>In which \(f(x) = \log p_m(x; \theta)\) is the function approximating log-likelihood the true distribution $p_d(.)$.</p><h3 id=notation>Notation<a hidden class=anchor aria-hidden=true href=#notation>#</a></h3><ul><li>\(p_d(x)\) true probability density function (p.d.f) of data.</li><li>\(p_n(x)\) p.d.f of noise generating distribution.</li><li>\(r(x) = \frac{1}{1+\exp(-x)}\) sigmoid function.</li><li>\(X = (x_1, &mldr; x_T); x \sim p_d(x)\) be the dataset of T observations.</li><li>\(Y = (y_1, &mldr; y_T); y \sim p_n(y)\) be the dataset of T artificially generated noise.</li><li>\(p_m(.; \theta)\) is estimation of \(p_d(.)\) parameterized by \(\theta\).</li></ul><h3 id=theorem>Theorem<a hidden class=anchor aria-hidden=true href=#theorem>#</a></h3><blockquote><p>\(\tilde{J}\) attains a maximum at \(f(.) = \log p_d(.)\). There are no other extrema if the noise density \(p_n(.)\) is chosen such it is nonzero whenever \(p_d(.)\) is nonzero.</p></blockquote><h3 id=proof>Proof<a hidden class=anchor aria-hidden=true href=#proof>#</a></h3><p>Let \(\hat{f}(x)\) be the optimal function that maximizes \(\tilde{J}\), and \(f(x)=\hat{f}(x) + \epsilon\eta(x)\).</p><p>\begin{equation}
\begin{aligned}
\tilde{J}(\theta) &= K(\epsilon) \\
&= \frac{1}{2}\mathbb{E}_{x, y} {
\log{
r\big(f(x) - \log{p_n(x)}\big)
} + \log{\big[
1 - r\big(f(y) - \log{p_n(y)}\big)
\big]}
} \\
&= \frac{1}{2}\underbrace{
\mathbb{E}_x {
\log r\big(
f(x) - \log p_n(x)
\big)
}
}_A +
\frac{1}{2} \underbrace{\mathbb{E}_y {
\log{\big[
1 - r\big(f(y) - \log{p_n(y)}\big)
\big]}
}}_B \\
\implies \frac{dK}{d\epsilon} &= \frac{dA}{d\epsilon} + \frac{dB}{d\epsilon}
\end{aligned}
\end{equation}</p><p>Expand the first term of $K(\epsilon)$</p><p>\begin{equation}
\begin{aligned}
A(\epsilon) &= \mathbb{E}_x {
\log r\big(
f(x) - \log p_n(x)
\big)
} \\
& = \int_x {
p_d(x) \log{
r\big(
\hat{f}(x) + \epsilon \eta(x) - \log p_n(x)
\big)
} dx
}
\end{aligned}
\end{equation}</p><p>Taking derivative of $A(\epsilon)$</p><p>\begin{equation}
\begin{aligned}
\frac{dA}{d\epsilon} &= \frac{1}{d\epsilon} \int_x {
p_d(x) \log{
r\big(
\hat{f}(x) + \epsilon \eta(x) - \log p_n(x)
\big)
} dx
} \\
& = \int_x {
p_d(x) \big[
\frac{1}{d\epsilon}\log{
r \big(
\underbrace{
\hat{f}(x) + \epsilon \eta(x) - \log p_n(x)
}_{g(\epsilon)}
\big)
}
\big]dx
} \\
& = \int_x{
p_d(x)
\frac{d\log{r}}{dr}
\frac{dr}{dg}
\frac{dg}{d\epsilon}
dx
} \\
& = \int_x{
p_d(x)
\frac{1}{r}
r(1-r)
\eta(x)
dx
} \\
& = \int_x{
p_d(x)
\big[1 - r\big( \hat{f}(x) + \epsilon \eta(x) - \log p_n(x)\big) \big]
\eta(x) dx
}
\end{aligned}
\end{equation}</p><p>Now let&rsquo;s turn our attention to the second term of $K(\epsilon)$</p><p>\begin{equation}
\begin{aligned}
B(\epsilon) &= \mathbb{E}_y {
\log\big[
1 - r\big(f(y) - \log{p_n(y)}\big)
\big]
} \\
& = \int_y {
p_n(y)
\log \big[
1 - r \big(
\underbrace{
\hat{f}(y) + \epsilon \eta(y) - \log p_n(y)
}_h
\big)
\big]dy
}
\end{aligned}
\end{equation}</p><p>Taking derivative of $B$ w.r.t $\epsilon$</p><p>\begin{equation}
\begin{aligned}
\frac{dB}{d\epsilon} &= \frac{1}{d\epsilon} \int_y{
p_n(y)\log{
\big[
1 - r\big( h(\epsilon)\big)
\big]
}dy
} \\
&= \int_y {
p_n(y)
\frac{d\log(1-r)}{d(1-r)}
\frac{d(1-r)}{dr}
\frac{dr}{dh}
\frac{dh}{d\epsilon}
dy
} \\
& = \int_y {
p_n(y)
\frac{1}{1-r}
(-1)
r(1-r)
\eta(y)
} \\
& = -\int_y{
p_n(y)
r\big(
\hat{f}(y) + \epsilon \eta(y) - \log p_n(y)
\big)
\eta(y) dy
}
\end{aligned}
\end{equation}</p><p>Substitute result from eq(4) and eq(6) to eq(2), $\frac{dK}{d\epsilon}$ is evaluated to $0$ at $\epsilon = 0$.</p><p>\begin{equation}
\begin{aligned}
\frac{dK}{d\epsilon}\big\vert_{\epsilon=0}
&= \frac{dA}{d\epsilon}\big\vert_{\epsilon=0}
+ \frac{dB}{d\epsilon}\big\vert_{\epsilon=0} \\
&= \int_x {
p_d(x)
\big[1 - r\big( \hat{f}(x) - \log p_n(x)\big) \big]
\eta(x) dx
} \\
& - \int_y{
p_n(y)
r \big(
\hat{f}(y) - \log p_n(y)
\big)
\eta(y) dy
} \\
& = 0
\end{aligned}
\end{equation}</p><p>Consider eq. (7), if the support for $x$ and $y$ are equal, which mean we integrate $x$ and $y$ over a same region, we can change $y$ to $x$ and rewrite eq.(7) as</p><p>\begin{equation}
\begin{aligned}
\frac{dK}{d\epsilon} \big\vert_{\epsilon = 0}
&= \int_x {
\underbrace{
p_d(x)
\big[1 - r\big( \hat{f}(x) - \log p_n(x)\big) \big]
}_C
\eta(x) dx
} \\
& - \int_x{
\underbrace{
p_n(x)
r \big(
\hat{f}(x) - \log p_n(x)
\big)
}_D
\eta(x) dx
} \\
& = \int_x{(C-D)\eta(x)dx} = 0 \quad \forall \eta(x)
\end{aligned}
\end{equation}</p><p>The equality in eq.(8) happend if and only if \(C=D\). This result easily leads to \(\hat{f}(x) = \log p_d(x)\).</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li><a href=https://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf>Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</a></li></ol></div><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://iamtu-dev.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/learning/>Learning</a></li><li><a href=http://localhost:1313/tags/probabilistic-ml/>Probabilistic-Ml</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/miscellanous/><span class=title>« Prev</span><br><span>Miscellanous</span>
</a><a class=next href=http://localhost:1313/posts/real-analysis/><span class=title>Next »</span><br><span>Real Analysis - Lecture notes</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>iamtu</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>